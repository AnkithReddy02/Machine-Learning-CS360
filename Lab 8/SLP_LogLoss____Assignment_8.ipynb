{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SLP-LogLoss || Assignment 8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSehflMxp3jF"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "\n",
        "def linear_predicted(x,w):\n",
        "  return np.dot(x,w)\n",
        "\n",
        "def logistic_predicted_sigmoid(x,w):\n",
        "  return 1/(1+ pow(math.e,-(np.dot(x,w))))\n",
        "  \n",
        "def linear_w_update(x,y,alpha,w):\n",
        "\n",
        "  for j in range(len(w)):\n",
        "    subtract_part = 0\n",
        "\n",
        "    for i in range(len(x)):\n",
        "      subtract_part = subtract_part + (linear_predicted(x[i],w)-y[i])*x[i][j]\n",
        "\n",
        "    w[j] = w[j] - (alpha*subtract_part)/len(x)\n",
        "\n",
        "  return w\n",
        "\n",
        "def logistic_w_update(x,y,alpha,w):\n",
        "\n",
        "  for j in range(len(w)):\n",
        "    subtract_part = 0\n",
        "\n",
        "    for i in range(len(x)):\n",
        "      subtract_part = subtract_part + (logistic_predicted_sigmoid(x[i],w)-y[i])*x[i][j]*(logistic_predicted_sigmoid(x[i],w))*(1-logistic_predicted_sigmoid(x[i],w))\n",
        "\n",
        "    w[j] = w[j] - (alpha*subtract_part)/len(x)\n",
        "\n",
        "  return w\n",
        "\n",
        "\n",
        "\n",
        "def error_linear(x,y,w):\n",
        "\n",
        "  J = 0\n",
        "  for i in range(len(x)):\n",
        "\n",
        "    J = J + pow((linear_predicted(x[i],w)-y[i]),2)\n",
        "\n",
        "  J = J/(2*len(x))\n",
        "\n",
        "  return J\n",
        "\n",
        "def error_logistic(x,y,w):\n",
        "  J = 0\n",
        "\n",
        "  for i in range(len(x)):\n",
        "    J = J + (y[i]*math.log(logistic_predicted_sigmoid(x[i],w),10)) + ((1-y[i])*math.log(1-logistic_predicted_sigmoid(x[i],w),10))\n",
        "\n",
        "  J = -J/(len(x))\n",
        "\n",
        "  return J\n",
        "\n",
        "\n",
        "\n",
        "def cal_MSE_batch(df,w,alpha,rho,epochs,showPlot):\n",
        "\n",
        "  a = np.array(df.values)\n",
        "\n",
        "  x = a[:,0:len(a[0])-1]\n",
        "\n",
        "  y = a[:,len(a[0])-1]\n",
        "\n",
        "  J = 0\n",
        "\n",
        "  prevJ = 0\n",
        "\n",
        "  itr = 0\n",
        "\n",
        "  epoch_graph = []\n",
        "  mse_graph = []\n",
        "\n",
        "  while True:\n",
        "\n",
        "    if(itr >= epochs):\n",
        "      break\n",
        "\n",
        "\n",
        "    h = []\n",
        "\n",
        "    \n",
        "\n",
        "    w = linear_w_update(x,y,alpha,w)\n",
        "    # w = logistic_w_update(x,y,alpha,w)\n",
        "\n",
        "    \n",
        "    J = 0\n",
        "\n",
        "    J = error_linear(x,y,w)\n",
        "\n",
        "    # print(J)\n",
        "    # J = error_logistic(x,y,w)\n",
        "\n",
        "    mse_graph.append(J)\n",
        "    epoch_graph.append(itr)\n",
        "\n",
        "\n",
        "    if(abs(J-prevJ) <= rho):\n",
        "      break\n",
        "\n",
        "    prevJ = J\n",
        "    itr = itr + 1\n",
        "\n",
        "  \n",
        "\n",
        "  if(showPlot==1):\n",
        "    plt.plot(epoch_graph,mse_graph)\n",
        "    plt.xlabel(\"EPOCHS\")\n",
        "    # naming the y axis\n",
        "    plt.ylabel(\"MSE\")\n",
        "    plt.show()\n",
        "  return w,J\n",
        "\n",
        "\n",
        "\n",
        "def cal_MSE_stoch(df,w,alpha,rho,epochs,showPlot):\n",
        "\n",
        "  a = np.array(df.values)\n",
        "\n",
        "  x = a[:,0:len(a[0])-1]\n",
        "\n",
        "  y = a[:,len(a[0])-1]\n",
        "\n",
        "  J = 0\n",
        "\n",
        "  prevJ = 0\n",
        "\n",
        "  itr = 0\n",
        "\n",
        "  epoch_graph = []\n",
        "  mse_graph = []\n",
        "\n",
        "  while True:\n",
        "\n",
        "    if(itr >= epochs):\n",
        "      break\n",
        "\n",
        "\n",
        "    h = []\n",
        "\n",
        "\n",
        "    for i in range(len(x)):\n",
        "\n",
        "      # predicted value must be changed\n",
        "      predicted_value = logistic_predicted_sigmoid(x[i],w)\n",
        "      # predicted_value = logistic_predicted_sigmoid(x[i],w)\n",
        "      h.append(predicted_value)\n",
        "\n",
        "      # gradient\n",
        "      # J = J + pow(predicted_value - y[i],2)\n",
        "\n",
        "      # stocastic - logloss\n",
        "      J = J + (y[i]*math.log(predicted_value,10)) + ((1-y[i])*math.log(1-predicted_value,10))\n",
        "\n",
        "      for j in range(len(w)):\n",
        "\n",
        "        # logloss-logistic, gradient-stocastic - MSE\n",
        "        w[j] = w[j] - alpha*(predicted_value-y[i])*x[i][j]\n",
        "\n",
        "        # logistic - MSE\n",
        "        # w[j] = w[j] - alpha*(predicted_value-y[i])*x[i][j]*predicted_value*(1-predicted_value)\n",
        "\n",
        "\n",
        "    # J = J/(2*len(x))\n",
        "\n",
        "    J = -J/(len(x))\n",
        "\n",
        "    \n",
        "\n",
        "    mse_graph.append(J)\n",
        "    epoch_graph.append(itr)\n",
        "\n",
        "    # shuffling.\n",
        "    df = df.sample(frac = 1)\n",
        "\n",
        "\n",
        "\n",
        "    if(abs(J-prevJ) <= rho):\n",
        "      break\n",
        "\n",
        "    prevJ = J\n",
        "    itr = itr + 1\n",
        "\n",
        "  \n",
        "  # print(mse_graph)\n",
        "  # print(epoch_graph)\n",
        "\n",
        "  if(showPlot != ''):\n",
        "    plt.plot(epoch_graph,mse_graph,label=str(showPlot))\n",
        "    plt.xlabel(\"EPOCHS\")\n",
        "    # naming the y axis\n",
        "    plt.ylabel(\"MSE\")\n",
        "    plt.legend()\n",
        "    # plt.show()\n",
        "  return w,J\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def SLP(df,W,alpha,rho,epochs,showPlot):\n",
        "\n",
        "  a = np.array(df.values)\n",
        "\n",
        "  X = a[:,0:len(a[0])-1]\n",
        "\n",
        "  Y = a[:,len(a[0])-1]\n",
        "\n",
        "  one = 0\n",
        "  zero = 0\n",
        "  two = 0\n",
        "\n",
        "  for f in Y:\n",
        "\n",
        "    if (f==1):\n",
        "      one+=1\n",
        "    elif (f==2):\n",
        "      two+=1\n",
        "    else:\n",
        "      zero+=1\n",
        "  \n",
        "\n",
        "  # print('one : ',one)\n",
        "  # print('two : ',two)\n",
        "  # print('zero : ', zero)\n",
        "\n",
        "  # for i in range(len(Y)):\n",
        "  #   if Y[i]==1:\n",
        "  #     Y[i] = 2\n",
        "  #   if Y[i]==2:\n",
        "  #     Y[i] = 1\n",
        "\n",
        "  # print(X)\n",
        "  # print(Y)\n",
        "\n",
        "  # X input Y output y for one hot encoding\n",
        "  # one hot encoding\n",
        "  y = []\n",
        "\n",
        "  for i in range(len(Y)):\n",
        "    yi = []\n",
        "    for j in range(len(classes)):\n",
        "      if(j==Y[i]):\n",
        "        yi.append(1)\n",
        "      else:\n",
        "        yi.append(0)\n",
        "\n",
        "    y.append(yi)\n",
        "\n",
        "\n",
        "\n",
        "  mse_graph = []\n",
        "  epoch_graph = []\n",
        "\n",
        "  itr = 1\n",
        "\n",
        "  prevJ = 0\n",
        "  while itr <= epochs :\n",
        "\n",
        "    # df = df.sample(frac = 1)\n",
        "\n",
        "    a = np.array(df.values)\n",
        "\n",
        "    X = a[:,0:len(a[0])-1]\n",
        "\n",
        "    Y = a[:,len(a[0])-1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    currJ = 0\n",
        "    for k in range(len(X)) :\n",
        "\n",
        "      x = X[k]\n",
        "\n",
        "      d = []\n",
        "\n",
        "      for w in W:\n",
        "        d.append(logistic_predicted_sigmoid(x,w))\n",
        "\n",
        "      sum = 0\n",
        "\n",
        "      for j in range(len(d)):\n",
        "        # sum += pow(d[j]-y[k][j],2)\n",
        "        sum += y[k][j]*math.log(d[j],10) + (1-y[k][j])*math.log(1-d[j],10)\n",
        "        \n",
        "      \n",
        "      # sum /= 2\n",
        "\n",
        "      currJ += sum\n",
        "\n",
        "\n",
        "      \n",
        "      for j in range(len(W)):\n",
        "        for i in range(len(W[j])):\n",
        "          W[j][i] = W[j][i] + alpha*(y[k][j] - d[j])*x[i]*d[j]*(1-d[j])\n",
        "\n",
        "    # currJ = currJ/len(X)\n",
        "    currJ = -currJ/len(X)\n",
        "\n",
        "    epoch_graph.append(itr)\n",
        "    mse_graph.append(currJ)\n",
        "\n",
        "    # print('currJ : ',currJ)\n",
        "    # print('prevJ : ', prevJ)\n",
        "\n",
        "    # print(abs(currJ - prevJ))\n",
        "\n",
        "\n",
        "    if(abs(currJ - prevJ) < rho):\n",
        "      break\n",
        "\n",
        "\n",
        "    prevJ = currJ\n",
        "    \n",
        "    itr += 1\n",
        "\n",
        "  # print(epoch_graph)\n",
        "  if(showPlot != ''):\n",
        "\n",
        "    plt.plot(epoch_graph,mse_graph,label=str(showPlot))\n",
        "    plt.xlabel(\"EPOCHS\")\n",
        "    # naming the y axis\n",
        "    plt.ylabel(\"MSE\")\n",
        "    plt.legend()\n",
        "    # plt.show()\n",
        "  \n",
        "  # print(itr)\n",
        "  return W,currJ  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def findAccuracy(classes,df,everyClassW,datasetName):\n",
        "\n",
        "  # Confusion Matrix\n",
        "  confusionMatrix = np.zeros((len(classes),len(classes)),dtype='int')\n",
        "\n",
        "\n",
        "\n",
        "  a = np.array(df.values)\n",
        "\n",
        "  x = a[:,0:len(a[0])-1]\n",
        "\n",
        "  y = a[:,len(a[0])-1]\n",
        "\n",
        "  # for i in range(len(y)):\n",
        "  #   if y[i]==1:\n",
        "  #     y[i] = 2\n",
        "  #   if y[i]==2:\n",
        "  #     y[i] = 1\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  # for each pattern predict H(Xi) for all classes then take max probability\n",
        "\n",
        "  correctlyPredicted = 0\n",
        "\n",
        "  for i in range(len(a)):\n",
        "\n",
        "    predictedForIthPattern = []\n",
        "    for c in classes:\n",
        "      predictedForIthPattern.append(logistic_predicted_sigmoid(everyClassW[c],x[i]))\n",
        "    # print(predictedForIthPattern)\n",
        "\n",
        "    # predicting the class.\n",
        "    predictedClass = predictedForIthPattern.index(max(predictedForIthPattern))\n",
        "\n",
        "\n",
        "    confusionMatrix[predictedClass][int(y[i])] += 1\n",
        "\n",
        "    if(predictedClass == y[i]):\n",
        "      correctlyPredicted += 1\n",
        "\n",
        "  print('Correctly Predicted : ',correctlyPredicted)\n",
        "  print('Total '+ datasetName +  ' Samples : ', len(a))\n",
        "  print(datasetName + ' Accuracy : ',(correctlyPredicted*100)/len(a))\n",
        "\n",
        "  print()\n",
        "  print('confusionMatrix :' )\n",
        "  print(confusionMatrix)\n",
        "  print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(len(confusionMatrix)):\n",
        "    print('precision for ',i,' class : ',confusionMatrix[i][i]/(sum(confusionMatrix[i])))\n",
        "\n",
        "  print()\n",
        "\n",
        "  colWiseSum_ConfusionMatrix = np.sum(confusionMatrix,axis=0)\n",
        "  for i in range(len(colWiseSum_ConfusionMatrix)):\n",
        "    print('recall for ',i,' class : ',confusionMatrix[i][i]/(colWiseSum_ConfusionMatrix[i]))\n",
        "\n",
        "  \n",
        "  print('\\n\\n')\n",
        "\n",
        "  return (correctlyPredicted*100)/len(a)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "      \n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V9qlN5OHqkLe",
        "outputId": "b2ff5c4e-c46d-4f73-d081-6a690b29ccc6"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "PRE-PROCCESSING STARTS\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "data = pd.DataFrame((datasets.load_wine()).data)\n",
        "target = pd.DataFrame((datasets.load_wine()).target)\n",
        "\n",
        "\n",
        "df = data;\n",
        "df = df/(df.max().max())\n",
        "df.insert(loc=len(df.columns),column = 'last',value=target)\n",
        "df.insert(loc=0,column='-1',value=[1 for i in range(len(df))])\n",
        "\n",
        "# shuffling DataFrame\n",
        "\n",
        "df = df.sample(frac = 1)\n",
        "\n",
        "'''\n",
        "\n",
        "for binary classification\n",
        "df = df[df['last']!=2]\n",
        "\n",
        "'''\n",
        "# df = df[df['last']!=2]\n",
        "\n",
        "# print(df)\n",
        "\n",
        "# print(df)\n",
        "\n",
        "# split the dataset in x:y:z\n",
        "\n",
        "x = 55\n",
        "y = 15\n",
        "z = 30\n",
        "train_set, reamining_set = train_test_split(df,train_size = x/100)\n",
        "validation_set, test_set = train_test_split(reamining_set,train_size = y/(y+z))\n",
        "print(len(train_set))\n",
        "print(len(validation_set))\n",
        "print(len(test_set))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "alphaarr = np.array([0.1,0.001,0.1,0.03,0.15])\n",
        "rhoarr = np.array([0.0001,0.011,0,0.001,0.0001])\n",
        "epocharr = np.array([100,200,1000,400,500])\n",
        "\n",
        "\n",
        "# df,w,alpha,rho,epochs\n",
        "\n",
        "\n",
        "'''\n",
        "PRE-PROCCESSING ENDS\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "classes = np.unique(np.array(list(df['last'])))\n",
        "\n",
        "print(classes)\n",
        "\n",
        "\n",
        "intialW = [random.uniform(-0.3,0.3) for i in range(len(df.columns)-1)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "W = [intialW.copy() for i in range(len(classes)) ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "bestHPIndex = 0\n",
        "minLoss = math.inf\n",
        "for i in range(len(epocharr)):\n",
        "  returnedW, J = SLP(validation_set,W.copy(),alphaarr[i],rhoarr[i],epocharr[i],'')\n",
        "  if(minLoss > J):\n",
        "    minLoss = J\n",
        "    bestHPIndex = i\n",
        "  # print(J)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "returnedW,J = SLP(validation_set,W.copy(),alphaarr[bestHPIndex],rhoarr[bestHPIndex],epocharr[bestHPIndex],'ok')\n",
        "returnedW,J = SLP(train_set,W.copy(),alphaarr[bestHPIndex],rhoarr[bestHPIndex],epocharr[bestHPIndex],'ok')\n",
        "\n",
        "print(bestHPIndex)\n",
        "\n",
        "print('TRAIN SET : \\n')\n",
        "findAccuracy(classes,train_set,returnedW.copy(),'TrainSet')\n",
        "\n",
        "print('\\nTEST SET : \\n')\n",
        "findAccuracy(classes,test_set,returnedW.copy(),'TestSet')\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(train_set)\n",
        "\n",
        "# print(test_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "   \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n",
            "27\n",
            "54\n",
            "[0 1 2]\n",
            "3\n",
            "TRAIN SET : \n",
            "\n",
            "Correctly Predicted :  63\n",
            "Total TrainSet Samples :  97\n",
            "TrainSet Accuracy :  64.94845360824742\n",
            "\n",
            "confusionMatrix :\n",
            "[[30  4  5]\n",
            " [ 1 33 24]\n",
            " [ 0  0  0]]\n",
            "\n",
            "precision for  0  class :  0.7692307692307693\n",
            "precision for  1  class :  0.5689655172413793\n",
            "precision for  2  class :  nan\n",
            "\n",
            "recall for  0  class :  0.967741935483871\n",
            "recall for  1  class :  0.8918918918918919\n",
            "recall for  2  class :  0.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TEST SET : \n",
            "\n",
            "Correctly Predicted :  39\n",
            "Total TestSet Samples :  54\n",
            "TestSet Accuracy :  72.22222222222223\n",
            "\n",
            "confusionMatrix :\n",
            "[[19  2  4]\n",
            " [ 1 20  8]\n",
            " [ 0  0  0]]\n",
            "\n",
            "precision for  0  class :  0.76\n",
            "precision for  1  class :  0.6896551724137931\n",
            "precision for  2  class :  nan\n",
            "\n",
            "recall for  0  class :  0.95\n",
            "recall for  1  class :  0.9090909090909091\n",
            "recall for  2  class :  0.0\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:401: RuntimeWarning: invalid value encountered in long_scalars\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72.22222222222223"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nwCUW-C8A2zI",
        "outputId": "408e5d91-6b6b-463b-8101-eede043bdf18"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# https://stackoverflow.com/questions/19155718/select-pandas-rows-based-on-list-index\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
        "\n",
        "\n",
        "print(df)\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "kf\n",
        "\n",
        "avgAccuracy = 0\n",
        "foldNum = 1\n",
        "for train_index, test_index in kf.split(np.array(df.values)):\n",
        "\n",
        "  \n",
        "\n",
        "  trainDf = df.iloc[train_index]\n",
        "  testDf = df.iloc[test_index]\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  print('FOLD : ',foldNum)\n",
        "\n",
        "  everyClassW,J = SLP(trainDf,W.copy(),alphaarr[bestHPIndex],rhoarr[bestHPIndex],epocharr[bestHPIndex],'ok')\n",
        "  accuracy = findAccuracy(classes,testDf,everyClassW.copy(),'testSet')\n",
        "  avgAccuracy += accuracy\n",
        "\n",
        "  print('--------------')\n",
        "\n",
        "\n",
        "  foldNum += 1\n",
        "\n",
        "  \n",
        "\n",
        "avgAccuracy /= 5\n",
        "\n",
        "print('AVG Accuracy : ',avgAccuracy)\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     -1         0         1         2  ...        10        11        12  last\n",
            "27    1  0.007917  0.001024  0.001274  ...  0.000607  0.001649  0.764881     0\n",
            "123   1  0.007768  0.003452  0.001268  ...  0.000435  0.001845  0.226190     1\n",
            "36    1  0.007905  0.000976  0.001690  ...  0.000649  0.001655  0.523810     0\n",
            "128   1  0.007363  0.000970  0.001369  ...  0.000530  0.001655  0.203571     1\n",
            "88    1  0.006929  0.001226  0.001464  ...  0.000595  0.001637  0.404762     1\n",
            "..   ..       ...       ...       ...  ...       ...       ...       ...   ...\n",
            "96    1  0.007030  0.001262  0.001631  ...  0.000565  0.001345  0.372024     1\n",
            "81    1  0.007571  0.001077  0.001310  ...  0.000690  0.001869  0.425000     1\n",
            "149   1  0.007786  0.002321  0.001405  ...  0.000339  0.000792  0.327381     2\n",
            "111   1  0.007452  0.001446  0.001292  ...  0.000536  0.001655  0.193452     1\n",
            "175   1  0.007899  0.002548  0.001345  ...  0.000351  0.000929  0.497024     2\n",
            "\n",
            "[178 rows x 15 columns]\n",
            "FOLD :  1\n",
            "Correctly Predicted :  26\n",
            "Total testSet Samples :  36\n",
            "testSet Accuracy :  72.22222222222223\n",
            "\n",
            "confusionMatrix :\n",
            "[[12  1  1]\n",
            " [ 0 14  8]\n",
            " [ 0  0  0]]\n",
            "\n",
            "precision for  0  class :  0.8571428571428571\n",
            "precision for  1  class :  0.6363636363636364\n",
            "precision for  2  class :  nan\n",
            "\n",
            "recall for  0  class :  1.0\n",
            "recall for  1  class :  0.9333333333333333\n",
            "recall for  2  class :  0.0\n",
            "\n",
            "\n",
            "\n",
            "--------------\n",
            "FOLD :  2\n",
            "Correctly Predicted :  23\n",
            "Total testSet Samples :  36\n",
            "testSet Accuracy :  63.888888888888886\n",
            "\n",
            "confusionMatrix :\n",
            "[[12  0  2]\n",
            " [ 0 11 11]\n",
            " [ 0  0  0]]\n",
            "\n",
            "precision for  0  class :  0.8571428571428571\n",
            "precision for  1  class :  0.5\n",
            "precision for  2  class :  nan\n",
            "\n",
            "recall for  0  class :  1.0\n",
            "recall for  1  class :  1.0\n",
            "recall for  2  class :  0.0\n",
            "\n",
            "\n",
            "\n",
            "--------------\n",
            "FOLD :  3\n",
            "Correctly Predicted :  20\n",
            "Total testSet Samples :  36\n",
            "testSet Accuracy :  55.55555555555556\n",
            "\n",
            "confusionMatrix :\n",
            "[[ 8  2  1]\n",
            " [ 0 12 13]\n",
            " [ 0  0  0]]\n",
            "\n",
            "precision for  0  class :  0.7272727272727273\n",
            "precision for  1  class :  0.48\n",
            "precision for  2  class :  nan\n",
            "\n",
            "recall for  0  class :  1.0\n",
            "recall for  1  class :  0.8571428571428571\n",
            "recall for  2  class :  0.0\n",
            "\n",
            "\n",
            "\n",
            "--------------\n",
            "FOLD :  4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:401: RuntimeWarning: invalid value encountered in long_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly Predicted :  30\n",
            "Total testSet Samples :  35\n",
            "testSet Accuracy :  85.71428571428571\n",
            "\n",
            "confusionMatrix :\n",
            "[[14  1  0]\n",
            " [ 1 16  3]\n",
            " [ 0  0  0]]\n",
            "\n",
            "precision for  0  class :  0.9333333333333333\n",
            "precision for  1  class :  0.8\n",
            "precision for  2  class :  nan\n",
            "\n",
            "recall for  0  class :  0.9333333333333333\n",
            "recall for  1  class :  0.9411764705882353\n",
            "recall for  2  class :  0.0\n",
            "\n",
            "\n",
            "\n",
            "--------------\n",
            "FOLD :  5\n",
            "Correctly Predicted :  25\n",
            "Total testSet Samples :  35\n",
            "testSet Accuracy :  71.42857142857143\n",
            "\n",
            "confusionMatrix :\n",
            "[[11  0  2]\n",
            " [ 1 14  7]\n",
            " [ 0  0  0]]\n",
            "\n",
            "precision for  0  class :  0.8461538461538461\n",
            "precision for  1  class :  0.6363636363636364\n",
            "precision for  2  class :  nan\n",
            "\n",
            "recall for  0  class :  0.9166666666666666\n",
            "recall for  1  class :  1.0\n",
            "recall for  2  class :  0.0\n",
            "\n",
            "\n",
            "\n",
            "--------------\n",
            "AVG Accuracy :  69.76190476190477\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}