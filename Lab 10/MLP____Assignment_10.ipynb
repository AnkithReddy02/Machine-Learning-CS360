{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP || Assignment 10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwABmWc26DUc"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "# delta2 starts from 0 and delta1 starts from 0\n",
        "def sigmoid(x,w):\n",
        "  return 1/(1+ pow(math.e,-(np.dot(x,w))))\n",
        "\n",
        "\n",
        "def predict(W1,W2,x,hiddenNeurons,hiddenBias):\n",
        "\n",
        "  h = [random.uniform(-0.3,0.3) for i in range(hiddenNeurons)] # or hiddenNeurons\n",
        "\n",
        "  d = [random.uniform(-0.3,0.3) for i in range(len(W2))]\n",
        "\n",
        "  h[0] = hiddenBias\n",
        "\n",
        "  # Input to hidden\n",
        "  for i in range(1,hiddenNeurons):\n",
        "    h[i] = sigmoid(x,W1[i-1]);\n",
        "\n",
        "    # Hidden to Output\n",
        "  for i in range(len(W2)):\n",
        "    d[i] = sigmoid(h,W2[i])\n",
        "\n",
        "\n",
        "  return d.index(max(d))\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def findAccuracy(test_set,W1,W2,hiddenNeurons,hiddenBias):\n",
        "\n",
        "  \n",
        "\n",
        "  a = np.array(df.values)\n",
        "\n",
        "  X = a[:,0:len(a[0])-1]\n",
        "\n",
        "  Y = a[:,len(a[0])-1]\n",
        "\n",
        "  confusionMatrix = np.zeros((len(classes),len(classes)),dtype='int')\n",
        "\n",
        "    \n",
        "  correctlyPredicted = 0\n",
        "\n",
        "  for k in range(len(X)) :\n",
        "    x = X[k]\n",
        "\n",
        "    predictedClass = predict(W1,W2,x,hiddenNeurons,hiddenBias)\n",
        "\n",
        "    if(predictedClass == Y[k]):\n",
        "      correctlyPredicted += 1\n",
        "\n",
        "    confusionMatrix[predictedClass][int(Y[k])] += 1\n",
        "\n",
        "  \n",
        "  print('Accuracy : ',correctlyPredicted*100/len(X))\n",
        "  print('\\n',confusionMatrix)\n",
        "  for i in range(len(confusionMatrix)):\n",
        "    print('precision for ',i,' class : ',confusionMatrix[i][i]/(sum(confusionMatrix[i])))\n",
        "\n",
        "  print()\n",
        "\n",
        "  colWiseSum_ConfusionMatrix = np.sum(confusionMatrix,axis=0)\n",
        "  for i in range(len(colWiseSum_ConfusionMatrix)):\n",
        "    print('recall for ',i,' class : ',confusionMatrix[i][i]/(colWiseSum_ConfusionMatrix[i]))\n",
        "\n",
        "  \n",
        "  print('\\n\\n')\n",
        "\n",
        "\n",
        "  return correctlyPredicted*100/len(X)\n",
        "\n",
        "    \n",
        "\n",
        "def MLP(df,W1,W2,hiddenNeurons,alpha,rho,epochs,showPlot):\n",
        "\n",
        "  a = np.array(df.values)\n",
        "\n",
        "  X = a[:,0:len(a[0])-1]\n",
        "\n",
        "  Y = a[:,len(a[0])-1]\n",
        "\n",
        "  \n",
        "  itr = 1\n",
        "\n",
        "  epoch_graph = []\n",
        "  mse_graph = []\n",
        "\n",
        "\n",
        "  # one hot encoding\n",
        "  y = []\n",
        "\n",
        "  for i in range(len(Y)):\n",
        "    yi = []\n",
        "    for j in range(len(classes)):\n",
        "      if(j==Y[i]):\n",
        "        yi.append(1)\n",
        "      else:\n",
        "        yi.append(0)\n",
        "\n",
        "    y.append(yi)\n",
        "\n",
        "\n",
        "\n",
        "  prevJ = 0\n",
        "\n",
        "  h = [random.uniform(-0.3,0.3) for i in range(hiddenNeurons)] # or hiddenNeurons\n",
        "\n",
        "  d = [random.uniform(-0.3,0.3) for i in range(len(W2))]\n",
        "\n",
        "  while itr <= epochs:\n",
        "\n",
        "    a = np.array(df.values)\n",
        "\n",
        "    X = a[:,0:len(a[0])-1]\n",
        "\n",
        "    Y = a[:,len(a[0])-1]\n",
        "\n",
        "    \n",
        "\n",
        "    delta2 = np.ones(len(W2))\n",
        "    delta1 = np.ones(len(W1))\n",
        "\n",
        "    currJ = 0\n",
        "\n",
        "\n",
        "    for k in range(len(X)) :\n",
        "      x = X[k]\n",
        "\n",
        "      # Input to hidden\n",
        "      for i in range(1,hiddenNeurons):\n",
        "        h[i] = sigmoid(x,W1[i-1]);\n",
        "\n",
        "      # Hidden to Output\n",
        "      for i in range(len(W2)):\n",
        "        d[i] = sigmoid(h,W2[i]);\n",
        "\n",
        "      # Local Gradient of Error in Each Output Node\n",
        "      for i in range(len(W2)):\n",
        "        delta2[i] = d[i] * (1-d[i]) * (y[k][i] - d[i]);\n",
        "\n",
        "      # Local Gradient of Error in Each Hidden Node\n",
        "      for i in range(len(W1)):\n",
        "        delta1[i] = 0\n",
        "        for j in range(len(W2)):\n",
        "          delta1[i] += delta2[j] * W2[j][i]\n",
        "        delta1[i] *= h[i] * (1 - h[i])\n",
        "\n",
        "      # Updation of Weights - Hidden to Output\n",
        "      for i in range(len(W2)):\n",
        "        for j in range(len(W2[i])):\n",
        "          W2[i][j] = W2[i][j] + alpha * delta2[i] * h[j];\n",
        "\n",
        "      # Updation of Weights - Input to Hidden\n",
        "      for i in range(len(W1)):\n",
        "        for j in range(len(W1[i])):\n",
        "          W1[i][j] = W1[i][j] + alpha * delta1[i] * x[j]\n",
        "\n",
        "      for i in range(len(W2)):\n",
        "        currJ += pow(y[k][i] - d[i],2)\n",
        "\n",
        "      \n",
        "    currJ /= 2*len(X)\n",
        "\n",
        "    epoch_graph.append(itr)\n",
        "    mse_graph.append(currJ)\n",
        "\n",
        "    # print('prev : ',prevJ, 'curr : ',currJ)\n",
        "\n",
        "    if(abs(currJ - prevJ) < rho):\n",
        "      break\n",
        "\n",
        "    prevJ = currJ\n",
        "\n",
        "    itr += 1  \n",
        "\n",
        "    \n",
        "  if(showPlot != ''):\n",
        "\n",
        "    plt.plot(epoch_graph,mse_graph,label=str(showPlot))\n",
        "    plt.xlabel(\"EPOCHS\")\n",
        "    # naming the y axis\n",
        "    plt.ylabel(\"MSE\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "  return W1,W2,h[0],currJ\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehGQtZLa6Tnz",
        "outputId": "2fbcbbea-da74-42b1-fbda-4846ca045790"
      },
      "source": [
        "data = pd.DataFrame((datasets.load_wine()).data)\n",
        "target = pd.DataFrame((datasets.load_wine()).target)\n",
        "\n",
        "\n",
        "df = data;\n",
        "df = df/(df.max().max())\n",
        "df.insert(loc=len(df.columns),column = 'last',value=target)\n",
        "df.insert(loc=0,column='-1',value=[1 for i in range(len(df))])\n",
        "\n",
        "# shuffling DataFrame\n",
        "\n",
        "df = df.sample(frac = 1)\n",
        "\n",
        "x = 55\n",
        "y = 15\n",
        "z = 30\n",
        "train_set, reamining_set = train_test_split(df,train_size = x/100)\n",
        "validation_set, test_set = train_test_split(reamining_set,train_size = y/(y+z))\n",
        "\n",
        "print('Train : ',len(train_set))\n",
        "print('Valid : ',len(validation_set))\n",
        "print(\"Test  : \",len(test_set))\n",
        "\n",
        "alphaarr = np.array([0.1,0.001,0.1,0.03,0.15,0.1])\n",
        "rhoarr = np.array([0.0001,0.01,0,0.001,0.0001,0])\n",
        "epocharr = np.array([100,500,1000,400,500,1000])\n",
        "hiddenNeuronsarr = np.array([4,36,30,3,5,20])\n",
        "\n",
        "classes = np.unique(np.array(list(df['last'])))\n",
        "\n",
        "# intialW = [random.uniform(-0.3,0.3) for i in range(len(df.columns)-1)]\n",
        "\n",
        "# W1 = [intialW.copy() for i in range(len(classes)) ]\n",
        "\n",
        "minHPIndex = 0\n",
        "minJ = None\n",
        "for i in range(len(alphaarr)):\n",
        "  intialW = [random.uniform(-0.3,0.3) for j in range(len(df.columns)-1)]\n",
        "  W1 = [intialW.copy() for j in range(hiddenNeuronsarr[i]-1)]\n",
        "  intialW = [random.uniform(-0.3,0.3) for j in range(hiddenNeuronsarr[i])]\n",
        "  W2 = [intialW.copy() for j in range(len(classes))]\n",
        "  w1,w2,hiddenBias,j = MLP(validation_set,W1.copy(),W2.copy(),hiddenNeuronsarr[i],alphaarr[i],rhoarr[i],epocharr[i],'')\n",
        "  if(minJ == None):\n",
        "    minJ = j\n",
        "  \n",
        "  if(j < minJ):\n",
        "    minHPIndex = i\n",
        "    minJ = j\n",
        "\n",
        "  print(j)\n",
        "  # break\n",
        "\n",
        "print('MinJ : ',minJ)\n",
        "print('minHPIndex : ',minHPIndex)\n",
        "\n",
        "intialW = [random.uniform(-0.3,0.3) for i in range(len(df.columns)-1)]\n",
        "W1 = [intialW.copy() for i in range(hiddenNeuronsarr[minHPIndex]-1)]\n",
        "intialW = [random.uniform(-0.3,0.3) for i in range(hiddenNeuronsarr[minHPIndex])]\n",
        "W2 = [intialW.copy() for i in range(len(classes))]\n",
        "\n",
        "# training\n",
        "trainW1,trainW2,hiddenBias,J = MLP(train_set,W1.copy(),W2.copy(),hiddenNeuronsarr[minHPIndex],alphaarr[minHPIndex],rhoarr[minHPIndex],epocharr[minHPIndex],'')\n",
        "\n",
        "#Testing\n",
        "findAccuracy(test_set,trainW1,trainW2,hiddenNeuronsarr[minHPIndex],hiddenBias)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train :  97\n",
            "Valid :  27\n",
            "Test  :  54\n",
            "0.3335218101343339\n",
            "0.35006468370969507\n",
            "0.2220516081157398\n",
            "0.35261325259240145\n",
            "0.33432804321926646\n",
            "0.21819002738795562\n",
            "MinJ :  0.21819002738795562\n",
            "minHPIndex :  5\n",
            "Accuracy :  69.66292134831461\n",
            "\n",
            " [[55  4  6]\n",
            " [ 1 62 35]\n",
            " [ 3  5  7]]\n",
            "precision for  0  class :  0.8461538461538461\n",
            "precision for  1  class :  0.6326530612244898\n",
            "precision for  2  class :  0.4666666666666667\n",
            "\n",
            "recall for  0  class :  0.9322033898305084\n",
            "recall for  1  class :  0.8732394366197183\n",
            "recall for  2  class :  0.14583333333333334\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69.66292134831461"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGHrs27AW2Cc",
        "outputId": "ffd7d1c2-9fbb-4886-81ea-cdf6586a9a0c"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# https://stackoverflow.com/questions/19155718/select-pandas-rows-based-on-list-index\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
        "\n",
        "\n",
        "print(df)\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "kf\n",
        "\n",
        "avgAccuracy = 0\n",
        "foldNum = 1\n",
        "for train_index, test_index in kf.split(np.array(df.values)):\n",
        "\n",
        "  \n",
        "\n",
        "  trainDf = df.iloc[train_index]\n",
        "  testDf = df.iloc[test_index]\n",
        "\n",
        "  print(train_index)\n",
        "  \n",
        "\n",
        "\n",
        "  print('FOLD : ',foldNum)\n",
        "\n",
        "  # training\n",
        "  trainW1,trainW2,hiddenBias,J = MLP(trainDf,W1.copy(),W2.copy(),hiddenNeuronsarr[minHPIndex],alphaarr[minHPIndex],rhoarr[minHPIndex],epocharr[minHPIndex],'')\n",
        "\n",
        "  #Testing\n",
        "  \n",
        "  avgAccuracy += findAccuracy(testDf,trainW1,trainW2,hiddenNeuronsarr[minHPIndex],hiddenBias)\n",
        "\n",
        "  print('--------------')\n",
        "\n",
        "\n",
        "  foldNum += 1\n",
        "\n",
        "  \n",
        "\n",
        "avgAccuracy /= 5\n",
        "\n",
        "print('AVG Accuracy : ',avgAccuracy)\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     -1         0         1         2  ...        10        11        12  last\n",
            "114   1  0.007190  0.000827  0.001488  ...  0.000554  0.001899  0.229167     1\n",
            "148   1  0.007929  0.001929  0.001417  ...  0.000327  0.000964  0.386905     2\n",
            "121   1  0.006881  0.001220  0.001923  ...  0.000554  0.002196  0.276786     1\n",
            "112   1  0.007000  0.001595  0.001738  ...  0.000732  0.001488  0.361310     1\n",
            "14    1  0.008560  0.001113  0.001417  ...  0.000714  0.001786  0.920833     0\n",
            "..   ..       ...       ...       ...  ...       ...       ...       ...   ...\n",
            "62    1  0.008137  0.000744  0.001143  ...  0.000732  0.001464  0.375000     1\n",
            "48    1  0.008393  0.001202  0.001429  ...  0.000637  0.001637  0.630952     0\n",
            "99    1  0.007315  0.001887  0.001315  ...  0.000845  0.001685  0.241667     1\n",
            "17    1  0.008232  0.000935  0.001560  ...  0.000673  0.001530  0.672619     0\n",
            "87    1  0.006935  0.000994  0.001560  ...  0.000810  0.001911  0.334524     1\n",
            "\n",
            "[178 rows x 15 columns]\n",
            "[ 36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177]\n",
            "FOLD :  1\n",
            "Accuracy :  70.2247191011236\n",
            "\n",
            " [[55  4  6]\n",
            " [ 0 61 33]\n",
            " [ 4  6  9]]\n",
            "precision for  0  class :  0.8461538461538461\n",
            "precision for  1  class :  0.648936170212766\n",
            "precision for  2  class :  0.47368421052631576\n",
            "\n",
            "recall for  0  class :  0.9322033898305084\n",
            "recall for  1  class :  0.8591549295774648\n",
            "recall for  2  class :  0.1875\n",
            "\n",
            "\n",
            "\n",
            "--------------\n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177]\n",
            "FOLD :  2\n",
            "Accuracy :  70.78651685393258\n",
            "\n",
            " [[53  4  5]\n",
            " [ 0 51 21]\n",
            " [ 6 16 22]]\n",
            "precision for  0  class :  0.8548387096774194\n",
            "precision for  1  class :  0.7083333333333334\n",
            "precision for  2  class :  0.5\n",
            "\n",
            "recall for  0  class :  0.8983050847457628\n",
            "recall for  1  class :  0.7183098591549296\n",
            "recall for  2  class :  0.4583333333333333\n",
            "\n",
            "\n",
            "\n",
            "--------------\n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177]\n",
            "FOLD :  3\n",
            "Accuracy :  71.34831460674157\n",
            "\n",
            " [[53  4  5]\n",
            " [ 0 55 24]\n",
            " [ 6 12 19]]\n",
            "precision for  0  class :  0.8548387096774194\n",
            "precision for  1  class :  0.6962025316455697\n",
            "precision for  2  class :  0.5135135135135135\n",
            "\n",
            "recall for  0  class :  0.8983050847457628\n",
            "recall for  1  class :  0.7746478873239436\n",
            "recall for  2  class :  0.3958333333333333\n",
            "\n",
            "\n",
            "\n",
            "--------------\n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
            " 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177]\n",
            "FOLD :  4\n",
            "Accuracy :  71.91011235955057\n",
            "\n",
            " [[53  4  5]\n",
            " [ 0 50 18]\n",
            " [ 6 17 25]]\n",
            "precision for  0  class :  0.8548387096774194\n",
            "precision for  1  class :  0.7352941176470589\n",
            "precision for  2  class :  0.5208333333333334\n",
            "\n",
            "recall for  0  class :  0.8983050847457628\n",
            "recall for  1  class :  0.704225352112676\n",
            "recall for  2  class :  0.5208333333333334\n",
            "\n",
            "\n",
            "\n",
            "--------------\n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142]\n",
            "FOLD :  5\n",
            "Accuracy :  72.47191011235955\n",
            "\n",
            " [[53  4  5]\n",
            " [ 0 45 12]\n",
            " [ 6 22 31]]\n",
            "precision for  0  class :  0.8548387096774194\n",
            "precision for  1  class :  0.7894736842105263\n",
            "precision for  2  class :  0.5254237288135594\n",
            "\n",
            "recall for  0  class :  0.8983050847457628\n",
            "recall for  1  class :  0.6338028169014085\n",
            "recall for  2  class :  0.6458333333333334\n",
            "\n",
            "\n",
            "\n",
            "--------------\n",
            "AVG Accuracy :  71.34831460674157\n"
          ]
        }
      ]
    }
  ]
}